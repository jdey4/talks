<!DOCTYPE html>
<html>

<head>
  <title>Discriminability</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <link rel="stylesheet" href="fonts/quadon/quadon.css">
  <link rel="stylesheet" href="fonts/gentona/gentona.css">
  <link rel="stylesheet" href="slides_style_i.css">
  <script type="text/javascript" src="assets/plotly/plotly-latest.min.js"></script>
</head>

<body>
  <textarea id="source">



<!-- TODO add slide numbers & maybe slide name -->

### Accidental Deviations in Human Connectomics


![:scale 40%](images/neurodata_blue.png)

Joshua T. Vogelstein | {[BME](https://www.bme.jhu.edu/),[CIS](http://cis.jhu.edu/), [ICM](https://icm.jhu.edu/), [KNDI](http://kavlijhu.org/)}@[JHU](https://www.jhu.edu/) | [neurodata](https://neurodata.io)
<br>
[jovo&#0064;jhu.edu](mailto:j1c@jhu.edu) | <http://neurodata.io/talks> | [@neuro_data](https://twitter.com/neuro_data)


---

## Outline 

- [Defining the Need for Reliability](#defn)
- [Quantifying Reliability](#statistics)
- [Properties of Discriminability](#props)
- [Results](#results)
- [Discussion](#disc)


---
name:defn

## Outline 

- Defining the Need for Reliability
- [Quantifying Reliability](#statistics)
- [Properties of Discriminability](#props)
- [Results](#results)
- [Discussion](#disc)


---

## What is Reproducibility?

- .ye[Reproducibility]: ability to replicate, or reproduce, a conclusion

--
- Closely related to repeatability
  - under a largely identical experiment, could we produce the same result two (or more) times?

--
- serves as a "first-pass" check for scientific utility
  - "If results cannot be reproduced, they are (generally) less useful"
- currently in a "reproducibility crisis"
  - many articles have highlighted failures to reproduce in neuroscience and psychology
---
### How do we address the Reproducibility Crisis?

- people frequently misinterpret $p$-values, so what happens if we ban them?
  - Goal: force people to make more modest scientific claims
  - tends to yield overstated claims, suggesting bans have the opposite of the intended effect
--

- Quantify reproducibility directly
  - measure each sample/individual several times, and look at the outputs
  - .ye["Garbage in; garbage out"]: if the measurements do not reproduce, inference on the data can't reproduce either
  - Fisher's "The Design of Experiments"
---
## Experimental Design (at present)
- Idea: design an experiment motivated by a particular scientific question
--

- Problem: this is not what is done in practice
  - Big datasets are expensive; large amounts of data are collected with many future uses in mind (not limited to one question)

--
  - The future questions .ye[may not even be known] when the data is acquired
--

- How can one design an experiment without knowing the question ahead of time?
  - Proposal: design experiments on the basis of .ye[discriminability]
---
name:statistics

## Outline 

- [Defining the Need for Reliability](#defn)
- Quantifying Reliability
- [Properties of Discriminability](#props)
- [Results](#results)
- [Discussion](#disc)


---
### Statistics for Quantifying Reproducibility

- most approaches tend to focus on the concepts of between-individual and within-individual summaries
--

- parametric approaches
  - reproducibility is achieved if most of the variability is between-individuals, rather than within-individuals
  - e.g. Intraclass Correlation Coefficient (.ye[ICC]) and Image Intraclass Correlation Coefficient (.ye[I2C2])
--

- non-parametric approaches
  - reproducibility is achieved if measurements from the same item are more similar to one another than measurements from different items
  - e.g. Fingerprinting (.ye[Finger.]) and DISCO (.ye[Kernel])
---
### Limitations of Existing Reproducibility Statistics
- Data: $N$ items in $d > 1$ dimensions measured $s \geq 2$ times each

| Statistic | Chief Limitation |
| :--- | :--- |
| ICC | univariate 
| I2C2 | does not generalize outside Gaussian framework 
| Finger. | overly greedy: only look at most similar measurement to the reference measurement 
| DISCO | struggles when $s$ is small 
---
### Discriminability Statistic: Data
- $n$ individuals measured $s = 2$ times each, for $N = n\cdot s$ total measurements
- generalizes to $s \geq 2$, but $s=2$ is simpler

<img src="images/discr/dummy_sim_sim.png"/>

---
### Discriminability Statistic: Step 1

- Compute $N \times N$ pairwise distance matrix between all measurements
- measurements are indexed first by individual identifier, and second by "measurement session"

<img src="images/discr/dummy_sim_dmtx.png"/>
---
### Discriminability Statistic: Step 2

- For each measurement, identify which measurements are from the same individual (<font color="green">green boxes</font>)
- let $\color{green}g$ be the total number of <font color="green">green boxes</font>

<img src="images/discr/dummy_sim_dmtx_match.png"/>
---
### Discriminability Statistic: Step 3
- For each measurement, identify measurements from other individuals that are more similar than the measurement from the same individual (<font color="orange">orange boxes</font>)
- let $\color{orange}f$ be the total number of <font color="orange">orange boxes</font>

<img src="images/discr/dummy_sim_dmtx_closer.png"/>
---
### Discriminability Statistic
- Discr. = $1 - \frac{\color{orange}f}{N(N-1) - \color{green}g} = 1 - \frac{\color{orange}{84}}{20\cdot 19 - \color{green}{20}} \approx .77$

<img src="images/discr/dummy_sim_repr.png"/>

- high discriminability: same-individual measurements are more similar than across-individual measurements
---

### Discriminability is Construct Valid
<img src="images/discr/dummy_sims.png" style="height: 350px"/>
- under the given construct (what the simulation is supposed to show), discriminability provides a sensible statistic
  - other approaches do not
---
name:props

## Outline 

- [Defining the Need for Reliability](#defn)
- [Quantifying Reliability](#statistics)
- Properties of Discriminability
- [Results](#results)
- [Discussion](#disc)

---
## Population Discriminability
- population discriminability $D$ is a .ye[property of the distribution] of measurements
- A sequence of items $x_i^k$ from individuals $i=1,..., N$ measured at time $k=1,..., s$
- $D = \mathbb P(\delta(x_i^k, x_i^{k'}) < \delta(x_i^k, x_j^{k''}))$
  - Probability that distances from measurements of the same individual are smaller than distances from measurements of different individuals
- Discr. is an .ye[unbiased estimator] of $D$
- as we see more data, Discr. converges to $D$ (.ye[asymptotically consistent])
---
## Simulation Setup
- Construct $3$ simple simulations where the data are describable in Gaussian (or non-Gaussian) framework
- level of "noise" in the simulation is varied
  <img src="images/discr/sims_sim.png" style="height: 450px"/>
---
## Test to determine Reliability
- Fundamental question: are the data discriminable at all?

<img src="images/discr/sims_os.png" style="height: 450px"/>
---
## Test to Compare Reliabilities
- Fundamental question: is one dataset more discriminable than another?

<img src="images/discr/sims_ts.png" style="height: 450px"/>
---
### Connecting Discriminability to Downstream Inference
- Fundamental question: does discriminability .ye[matter] for inference?

##### Assumptions
Data follows Gaussian mixture model plus additive Gaussian noise

##### Theorem 1
$D$ provides a lower bound on the predictive accuracy of a subsequent classification task, and consequently
##### Corollary 2
a strategy with a higher $D$ provably provides a higher bound on predictive accuracy than a strategy with a lower $D$
---
### Discriminability and Predictive Accuracy
- as accuracy decreases, Discr. decreases proportionally
<img src="images/discr/sims_acc.png" style="height: 450px"/>
---
name:results

## Outline 

- [Defining the Need for Reliability](#defn)
- [Quantifying Reliability](#statistics)
- [Properties of Discriminability](#props)
- Results
- [Discussion](#disc)
---
## What data will we be using?

- CoRR metadataset
- $N>1,700$ individuals imaged across $26$ different datasets
  - All individuals have anatomical MRI and fMRI scans needed to estimate a connectome
  - Most of the data is test-retest: individuals are measured $s \geq 2$ times under a similar experimental design
---
## Analysis Procedure
- For all $N>1,700$ individuals, process each measurement exhaustively across $192$ different pre-processing pipelines
  1. Registration: alignment of brains (2 options: ANTs/FSL)
  2. Frequency Filtering: removing spurious fluctuations (2 options: Y/N)
  3. Scrubbing: removing timepoints where the subject moved substantially (2 options: Y/N)
  4. Global Signal Regression: removing spatial average at each timepoint (2 options: Y/N)
  5. Parcellation choice: making the data smaller (4 options)
  6. Edge Weights: how do we quantify functional connectivity (3 options: Raw, Log, Pass-to-Rank)

$192 = 2 \times 2 \times 2 \times 2 \times 4 \times 3$ 
- all options represent strategies experts consider useful
---
### Pre-processing has a major impact on discriminability
<img src="images/discr/fmri_cmp.png" style="height: 420px"/>

- Consequence: choosing how to pre-process your data matters
---
### Marginally most discriminabile options tend to be best global options
<img src="images/discr/individual_methods.png" style="height: 200px"/>
- Best pipeline marginally (FNNGCP) is second best pipeline overall, and not much worse (2-sample test, p=.14) than the best pipeline FNNNCP
- Consequence: we may not need to always try every pre-processing strategy every time
---
### Selection via Discriminability improves inference
- For each pre-processing strategy, for each dataset, compute:
1. Within-dataset Discr.
2. Demographic effects (sex and age) within the dataset via Distance Correlation (DCorr)
- Within a single dataset, regress demographic effect on Discr.
- Question: does a higher discriminability tend to yield larger effects for known biological signals?
---
### Selection via Discriminability improves inference
<img src="images/discr/dependence.png" style="height: 400px"/>
- Consequence: maximizing discriminability in general improves downstream inference
---
name:disc

## Outline 

- [Problem Space](#prob)
- [Defining and Quantifying Reliability](#statistics)
- [Properties of Discriminability](#props)
- [Results](#results)
- Discussion

---
### Contributions
1. Demonstrate that discriminability quantifies the contributions of systematic and accidental deviations
2. Formalize tests for assessing and comparing discriminabilities within and between collection strategies
3. Provide theoretical motivation for discriminability in connection with predictive accuracy
4. Illustrate the value of discriminability for neuroscience and (not discussed) genomics data
5. Code implementations in [python](https://github.com/neurodata/hyppo) and [R](https://github.com/neurodata/r-mgc)
---
### Connections to Energy Statistics
- energy statistics provide statistics that are functions of distances between measurements, like discriminability
- both approaches make relatively few assumptions
- discriminability 2-sample test is a comparison of K-sample tests in the energy statistics literature
- energy statistics tend to perform well when we have more replicates (e.g., DISCO)
---
### Extending Discriminability
- use of distances allows for trivial modification for non-Euclidean measurements
  - e.g., speech or text data may make sense with different distance functions
- measurements that consist of multiple measurements themselves
  - many applications will aggregate many measurements into a single "raw derivative"
  - e.g., fMRI is an aggregation of multiple measurements made over $t$ timepoints
  - if we only have one measurement that consists of many sub-measurements, can split the sub-measurements into multiple measurements
  - e.g., taking a single fMRI and splitting into two fMRI with $\frac{t}{2}$ timepoints each
---
## Limitations
- experimental design is not "one-size-fits-all"
  - future scientific questions will still need to consider the question of interest
  - e.g., an analysis of task fMRI may not want to use a pre-processing pipeline with global signal regression, but for resting-state fMRI, this may not be an issue
- Reliability is not a pre-requisite, nor a surrogate, for practical utility
  - categorical covariates are meaningful but not discriminable
  - fingerprints are discriminable but not typically biological useful
- Reliability statistics are not immune to sample characteristics
  - confounds such as age may inflate discriminability
---
## Key Contributors & Links
- People: Eric Bridgeford, Zeyi Wang, Shangsi Wang, Zhi Yang, Ting Xu, Cameron Craddock, Jayanta Dey, Greg Kiar, William Gray-Roncal, Carlo Coulantoni, Christopher Douville, Carey E. Priebe, Brian Caffo, Michael Milham, Xi-Nian Zuo
- Places and Organizations: Consortium for Reliability and Reproducibility (CoRR), Johns Hopkins University, Shanghai Jiaotong University, Child Mind Institute, Beijing Normal University, Nanning Normal University, University of Chinese Academy of Sciences, Progressive Learning, Neurodata
- [BioRxiv Manuscript](https://www.biorxiv.org/content/10.1101/802629v6)
- Code implementations in [python](https://github.com/neurodata/hyppo) and [R](https://github.com/neurodata/r-mgc)
---
</textarea>
  <!-- <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js"></script> -->
  <!-- <script src="remark-latest.min.js"></script> -->
  <script src="remark-latest.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
  <script type="text/javascript">

    var options = {};
    var renderMath = function () {
      renderMathInElement(document.body);
      // or if you want to use $...$ for math,
      renderMathInElement(document.body, {
        delimiters: [ // mind the order of delimiters(!?)
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
          { left: "\\[", right: "\\]", display: true },
          { left: "\\(", right: "\\)", display: false },
        ]
      });
    }

    remark.macros.scale = function (percentage) {
      var url = this;
      return '<img src="' + url + '" style="width: ' + percentage + '" />';
    };

    // var slideshow = remark.create({
    // Set the slideshow display ratio
    // Default: '4:3'
    // Alternatives: '16:9', ...
    // {
    // ratio: '16:9',
    // });

    var slideshow = remark.create(options, renderMath);


  </script>
</body>

</html>